import torch
import pandas as pd
from IPython.display import Audio
from pprint import pprint
import os

class SpeechTimingModelClient:
    '''
        Class used for applying the silero_vad model to .wav data.
        Requires metadata.csv file exist as generated by WAVCrawler.produceMetadata() call

        Attributes:
            _model: the silero_vad
            _utils: structure containing utility functions for applying _model
            _data_path: path to the data folder where metadata.csv is stored
    '''

    _model, _utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',
                              model='silero_vad',
                              force_reload=False)
    _data_path = os.path.join(os.path.dirname(os.path.dirname(os.path.realpath(__file__))), 'data')
    _sampling_rate = 16000

    def processMetadata(self):
        ''' Applies silero_vad to .wav files pointed to in metadata.csv, stores new file 
            language_output.csv which contains all the information from metadata.csv plus
            the following columns:
                has_speech: True if any speech was detected in the file, else False
                speech_starts: ':'-delimited values denoting when speech began in the file
                speech_ends: ':'-delimited values denoting when speech ended in the file
         '''
        (get_speech_timestamps, _, read_audio, *_) = SpeechTimingModelClient._utils
        metadata_df = pd.read_csv(os.path.join(SpeechTimingModelClient._data_path, "metadata.csv"))
        total_rows = metadata_df.shape[0]
        has_speech_list = []
        start_list = []
        end_list = []
        for i in range(0, total_rows):
            file_example = os.path.join(SpeechTimingModelClient._data_path, 'wavs', metadata_df.at[i, 'File'])
            try:
                wav = read_audio(file_example, sampling_rate=SpeechTimingModelClient._sampling_rate)
            except:
                has_speech_list.append('ERROR')
                start_list.append('ERROR')
                end_list.append('ERROR')
                continue

            speech_timestamps = get_speech_timestamps(wav, SpeechTimingModelClient._model, sampling_rate=SpeechTimingModelClient._sampling_rate)
            if(not speech_timestamps):
                has_speech_list.append('false')
                start_list.append('')
                end_list.append('')
                continue

            starts = ""
            ends = ""
            for pair in speech_timestamps:
                starts += str(pair['start']) + ":"
                ends += str(pair['end']) + ":"
            starts = starts[:-1]
            ends = ends[:-1]
            has_speech_list.append('true')
            start_list.append(starts)
            end_list.append(ends)
            
        metadata_df['has_speech'] = has_speech_list
        metadata_df['speech_starts'] = start_list
        metadata_df['speech_ends'] = end_list
        metadata_df.to_csv(os.path.join(SpeechTimingModelClient._data_path, "speech_timing_output.csv"), index=False)